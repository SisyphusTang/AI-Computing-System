# 一、 python基础

## 1. python类

![](https://cdn.staticaly.com/gh/SisyphusTang/Picture-bed@master/20221109/class类.nnmqqinvyww.webp)

**在上述类的方法当中，函数参数的`self`参数是必须要有，其余参数是可选的**

## 2. Numpy库

**这里的Numpy数组的算术运算，需要保持元素个数相同，即 element-wise product**

element-wise product 对应元素相乘

当然，也可以让各个元素和单个标量元素进行运算 如 `x / 2`就是整体元素都除以2

```python
import numpy as np #导入numpy库
x = np.array([1,2,3])
y = np.array([2,4,18])
print(x + y)
print(x - y)
print(x * y)
print(x / y)
```

### 2.1 numpy的多维数组

#### 矩阵的乘法

**！注意！**  `*`是代表对应元素相乘，`numpy.dot()`才是真正的矩阵相乘的结果 

```python
x = np.array([[1,2],[3,4]])
y = np.array([[1],[2]])
# y = np.array([[3,0],[0,6]])
out = np.dot(x,y)
print(out)
```

数学上将一维数组称为**向量**， 将二维数组称为**矩阵**。另外，可以将一般化之后的向量或矩阵等统 称为**张量（tensor）**

#### 访问元素的其它方法

```python
x = np.array([[1,2],[3,4]])   
> x[0] #第0行
> x[0][1] #第0行第1列的元素
> for item in x #遍历元素
> x = x.flatten() #x转换为一维数组
> x[x>2] #输出所有>2的元素的值
```

实际上，如果是运算量大的处理对象，用 C/C++写程 序更好。为此，当 Python中追求性能时，人们会用 C/C++来实现 处理的内容。Python则承担“中间人”的角色，负责调用那些用 C/ C++写的程序。NumPy中，主要的处理也都是通过C或C++实现的。 因此，我们可以在不损失性能的情况下，使用 Python便利的语法。

## 3. Matplotlib 数据可视化

### 显示函数图像

```python
import numpy as np
import matplotlib.pyplot as plt
#生成数据
x  = np.arange(-6,6,0.1) #（0，6）以0.1为单位生成0到6的数据
y  = np.sin(x)
y1 = np.cos(x)
#绘制图像
plt.plot(x, y, label="sin")
plt.plot(x, y1, linestyle = "--", label="cos") # 用虚线绘制
plt.xlabel("x")  
plt.ylabel("y")  #x轴和y轴标签
plt.title('sin & cos')  #标题
plt.legend() #加这个图列才能显示出来
plt.show()
```

### 显示图片

```python
import matplotlib.pyplot as plt
from matplotlib.image import imread
img = imread('T:\Download\wallerpaper.jpg') # 读入图像（设定合适的路径！）
plt.imshow(img)
plt.show()
```





# 二、 感知机perceptron

感知机接收多个输入信号，输出一个信号。x1、x2是输入信号， y是输出信号，w1、w2是权重（w是weight的首字母）。图中的○称为“神 经元”或者“节点”。

![](https://cdn.staticaly.com/gh/SisyphusTang/Picture-bed@master/20221109/感知机模型.161lse5cjilc.webp)

即达到一定阙值之后，神经元才会被激活

**w1,w2表示参数的重要性，而偏置b表示的是整个神经元被激活的容易程度**



### 为什么单层的感知机不能解决非线性问题

对于或门，一共四个点，我们可以在坐标轴当中用小三角表示取1的情况，小圆圈表示取0的情况

![](https://cdn.staticaly.com/gh/SisyphusTang/Picture-bed@master/20221109/或门方程组.33xgivpmwig0.png)

可以在数轴下表示为如下的情况

![](https://cdn.staticaly.com/gh/SisyphusTang/Picture-bed@master/20221109/或门表示的直线.5evdoehzy4k0.webp)

也就是可以用一条直线来划分区域，所以对于或门可以找到对应的参数w1,w2以及b满足条件

然而对于亦或，表示的点有如下情况

![](https://cdn.staticaly.com/gh/SisyphusTang/Picture-bed@master/20221109/亦或.4s3ynea4rk40.webp)

无法用一条直线来划分出两个区域，因此，这类问题**是线性不可分的问题，也就是非线性的**

![](https://cdn.staticaly.com/gh/SisyphusTang/Picture-bed@master/20221109/亦或-非线性.u6dbfc4d2ao.webp)

感知机通过叠 加层能够进行非线性的表示，理论上还可以表示计算机进行的处理





# 三、神经网络

神经网络的一 个重要性质是它可以自动地从数据中学习到合适的权重参数。

**神经网络的激活函数必须使用非线性函数,线性函数的问题在于，不管如何加深层数，总是存在与之等效的“无 隐藏层的神经网络”**

把线性函数 h(x) = cx 作为激活 函数，把y(x) = h(h(h(x)))的运算对应3层神经网络A。这个运算会进行 y(x) = c × c × c × x的乘法运算，但是同样的处理可以由y(x) = ax（注意， a = c 3 ）这一次乘法运算（即没有隐藏层的神经网络）来表示

使用线性函数时，无法发挥多层网络带来的优势

神经网络的简单结构如下:

![](https://cdn.staticaly.com/gh/SisyphusTang/Picture-bed@master/20221109/神经网络结构.3w415mebiw40.png)

## 多维数组的运算

数组的维数可以用`np.dim()`函数来获得,数组的形状可以用`np.shape（）`来获得每一维的情况

输出层所用的激活函数，要根据求解问题的性质决定。一般地，回归问题可以使用恒等函数，二元分类问题可以使用 sigmoid函数，多元分类问题可以使用 softmax函数。关于输出层的激活函数，我
们将在下一节详细介绍。  



## softmax函数

机器学习的问题大致可以分为分类问题和回归问题。  

 恒等函数会把输入按原样输出

分类问题当中使用softmax()函数

![](https://cdn.staticaly.com/gh/SisyphusTang/Picture-bed@master/20221109/softmax函数.vn5a1h108xs.webp)

**softmax函数会存在溢出的情况**

softmax函数在进行运算时，加上或者减去某个函数并不会改变运算的结果。**一般使用的是输入信号当中的最大值**

![](https://cdn.staticaly.com/gh/SisyphusTang/Picture-bed@master/20221109/softmax函数优化.4hfd1a4of480.webp)



softmax函数的输出是0.0到1.0之间的实数，并且函数的输出总和是1，因为这个性质，我们才可以softmax函的输出解释为"概率"

softmax函数的一些性质

+ 输出的是 0.0 - 1.0之间的实数
+ 所有的元素加起来之和为1，可以被当作概率来使用
+ 元素之间的大小关系是相对的，不会改变对应的大小关系
+ 神经网络把输出值最大的神经元作为识别结果





## 手写数字的识别

MNIST是机器学习领域最有名的数据集之一  

**预处理： ** 提高识别性能和学习的效率

**白化： **     将数据整体的分布形状均匀化的方法

```python
import sys, os
import pickle
sys.path.append(os.pardir)
import numpy as np
from dataset.mnist import load_mnist
from PIL import Image

def sigmoid(x):
    return  1 / (1 + np.exp(-x))

def softmax(a):
    c = np.max(a)
    #上下同时减去一个常数 整个式子的值并不改变
    exp_a = np.exp(a - c)
    sum_exp_a = np.sum(exp_a)
    y = exp_a / sum_exp_a
    return y

def get_data(): 
    # 第一个参数将输入图像正规化为0.0-1.0的值
    # 第二个参数表示是否将参数展开为一维数组
    # 第三个参数表示是否将标签存为[0,0,1,000..]这种形式
    (x_train, t_train),(x_test,t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)
    return x_test,t_test

# 读取sample_weight.pkl当中学习到的权重参数，权重和偏置
def init_network():
    with open("sample_weight.pkl",'rb') as f:
        network  = pickle.load(f)
    
    return network

def predict(network,x):
    # 图像的格式为28*28 = 784
    # W1 (784,50) W2(50,100) W3(100,10)  b1(50,)  b2(100,) b3(10,)
    W1,W2,W3 = network['W1'],network['W2'],network['W3']
    b1,b2,b3 = network['b1'],network['b2'],network['b3']
    a1 = np.dot(x,W1) + b1
    z1 = sigmoid(a1)
    a2 = np.dot(z1,W2) + b2
    z2 = sigmoid(a2)
    a3 = np.dot(z2,W3) + b3
    y = softmax(a3)

    return y


# x是测试图像 t是图像对应的标签
x,t = get_data()
network = init_network()
accuracy_cnt = 0
for i in range(len(x)):
    # 返回的y是一个十个数字的元组
    y = predict(network,x[i])
    # p是最高概率的索引
    p = np.argmax(y)
    print(p)
    if p == t[i]:
        accuracy_cnt += 1

print("Accuracy:" + str(float(accuracy_cnt) / len(x) ))
```



## 批处理

大多数处理数值计算的库都进行了能够高效处理大型数组运算的最优化。并且，在神经网络的运算中，当数据传送成为瓶颈时，批处理可以减轻数据总线的负荷

代码与上述代码不同的部分

```python
x, t = get_data()
network = init_network()
batch_size = 100 # 批数量
accuracy_cnt = 0
for i in range(0, len(x), batch_size):
    # i是一个起始位置
    # x_batch是取序列中的一段
    x_batch = x[i:i+batch_size]
    # y返回的是一个(batch_size,10)的二维元组
    y_batch = predict(network, x_batch)
    # axis=1 表示沿着第一维的方向进行寻找 找到最大的那个值的下标 p也是一个元组
    p = np.argmax(y_batch, axis=1)
    # 两个numpy的array比较 返回的是[true,false,true,false。。。]这种结果
    accuracy_cnt += np.sum(p == t[i:i+batch_size])
print("Accuracy:" + str(float(accuracy_cnt) / len(x)))
```

