对于计算图，正向计算（forward propagation）、反向计算（backward  propagation）都是局部计算，假设y为输出、x为输入，正向计算只用考虑y = f (x)，同理，BP反向计算某一结点也只需要用求输出关于输入的偏导数即可。

![计算图求导](https://cdn.staticaly.com/gh/SisyphusTang/Picture-bed@master/20230619/计算图求导.34hjn8sqakk0.webp)

> 上图的z、t、x分别是不同阶段的输入和输出



### 加法的反向传播

![加法反向传播计算图](https://cdn.staticaly.com/gh/SisyphusTang/Picture-bed@master/20230619/加法反向传播计算图.24o9af7x2pog.webp)

> 注：这里的L 是上层传过来的值，假设加法位于中间的某一个环节

**由图可知，加法节点的反向传播只是将输入信号输出到下一个节点，并不改变信号**

### 乘法的反向传播

**乘法的反向传播会乘以输入信号的翻转值，乘法的反向传播需要正向传播时的输入信号值。因此，实现乘法节点的反向传播时，要保存正向传播的输入信号。**

![乘法反向传播的计算图](https://cdn.staticaly.com/gh/SisyphusTang/Picture-bed@master/20230619/乘法反向传播的计算图.3kbnhdlh9z60.webp)

### Affine反向传播算法

仿射变换计算图

注：其中X为1×2的数组、W为2×3的数组、x.dot(w)为1×3的数组，B为1×3的数组，结果Y为1×3的数组

![仿射变换计算图](https://cdn.staticaly.com/gh/SisyphusTang/Picture-bed@master/20230619/affine仿射变换.3oax0zbrwmg0.webp)

仿射变换逆向传播反向计算图

![仿射变换逆向传播反向计算图](https://cdn.staticaly.com/gh/SisyphusTang/Picture-bed@master/20230619/Affine仿射变换反向计算图.gvqifnh441s.webp)

**注意**：这里反向求导的结果（求至入口）都是最后的损失函数对初始参数的偏导数



softmax 函数记为Softmax 层，交叉熵误差记为Cross Entropy Error 层



### 对应误差反向传播法的神经网络的实现

